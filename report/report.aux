\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lstm}
\citation{resnet}
\citation{transformers}
\citation{BengioLBL15}
\citation{EqProp}
\citation{BengioLBL15}
\citation{Eric2018}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Work}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Research Questions}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Project Outline}{2}{subsection.1.3}\protected@file@percent }
\citation{mnist}
\@writefile{toc}{\contentsline {section}{\numberline {2}Deep Learning}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Mathematical Notation}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dataset}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Maximum Likelihood Estimation}{3}{subsection.2.3}\protected@file@percent }
\newlabel{sec:MLE}{{2.3}{3}{Maximum Likelihood Estimation}{subsection.2.3}{}}
\citation{Goodfellow-et-al-2016}
\newlabel{eq:negative-log-likelihood}{{4}{4}{Maximum Likelihood Estimation}{equation.2.4}{}}
\newlabel{eq:regression-loss-deriv}{{6}{4}{Maximum Likelihood Estimation}{equation.2.6}{}}
\newlabel{eq:softmax}{{7}{5}{Maximum Likelihood Estimation}{equation.2.7}{}}
\newlabel{eq:softmax-derivative}{{12}{5}{Maximum Likelihood Estimation}{equation.2.12}{}}
\newlabel{eq:partial-log-softmax}{{15}{6}{Maximum Likelihood Estimation}{equation.2.15}{}}
\newlabel{eq:cross-entropy-loss-deriv}{{22}{6}{Maximum Likelihood Estimation}{equation.2.22}{}}
\citation{he2015delving}
\citation{rumelhart1986learning}
\citation{noekland2016direct}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feed-forward Neural Networks}{7}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Weight initialization}{7}{subsubsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Back-propagation}{7}{subsection.2.5}\protected@file@percent }
\newlabel{sec:backprop}{{2.5}{7}{Back-propagation}{subsection.2.5}{}}
\citation{ioffe2015batch}
\newlabel{eq:dLdW1}{{23}{8}{Back-propagation}{equation.2.23}{}}
\newlabel{eq:delta-terms}{{25}{8}{Back-propagation}{equation.2.25}{}}
\newlabel{eq:weight-update}{{26}{8}{Back-propagation}{equation.2.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Batch normalization}{8}{subsection.2.6}\protected@file@percent }
\newlabel{eq:batch-norm}{{30}{9}{Batch normalization}{equation.2.30}{}}
\citation{hunsberger2015spiking}
\citation{PredictiveCodingNetworks}
\citation{hebb1949}
\@writefile{toc}{\contentsline {section}{\numberline {3}Biologically plausible deep learning}{10}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Biological neurons}{10}{subsection.3.1}\protected@file@percent }
\newlabel{sec:neurons}{{3.1}{10}{Biological neurons}{subsection.3.1}{}}
\citation{Bi10464}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of biological neuron by BruceBlaus - Own work, CC BY 3.0 \footnotemark \relax }}{11}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bio-neuron}{{1}{11}{Illustration of biological neuron by BruceBlaus - Own work, CC BY 3.0 \protect \footnotemark \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Biological constraints}{11}{subsection.3.2}\protected@file@percent }
\newlabel{sec:biological-constraints}{{3.2}{11}{Biological constraints}{subsection.3.2}{}}
\citation{BengioLBL15}
\citation{Eric2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Biological violations of backprop and deep learning}{12}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Spiking neural networks}{12}{subsection.3.3}\protected@file@percent }
\citation{Boht2000SpikePropBF}
\citation{eshraghian2021training}
\citation{Eric2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Training spiking neural networks}{13}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Leaky-Integrate-and-Fire neurons}{13}{subsubsection.3.3.2}\protected@file@percent }
\citation{hunsberger2015spiking}
\newlabel{fig:rate-function}{{2a}{14}{Interleaved plot of original rate function, $r(j)$ (orange), and smoothed version, $r_\rho (j)$ (blue).\relax }{figure.caption.5}{}}
\newlabel{sub@fig:rate-function}{{a}{14}{Interleaved plot of original rate function, $r(j)$ (orange), and smoothed version, $r_\rho (j)$ (blue).\relax }{figure.caption.5}{}}
\newlabel{fig:poisson-rate}{{2b}{14}{Theoretical (orange) and simulated spike rates (blue) as functions of input current.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:poisson-rate}{{b}{14}{Theoretical (orange) and simulated spike rates (blue) as functions of input current.\relax }{figure.caption.5}{}}
\newlabel{fig:rate-scaling}{{2c}{14}{Scaling of the rate function in the interval $[0; 10]$ to mimic ReLU.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:rate-scaling}{{c}{14}{Scaling of the rate function in the interval $[0; 10]$ to mimic ReLU.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Plots of smoothed, poisson coded and ReLU-like rate functions, respectively.\relax }}{14}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Poisson rate coding}{14}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Low-pass alpha-filter}{14}{subsubsection.3.3.4}\protected@file@percent }
\newlabel{eq:alpha-filter}{{37}{15}{Low-pass alpha-filter}{equation.3.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Shadow training spiking neural networks}{15}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Activation scaling}{15}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Rate estimation using alpha-filter}{15}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Fusing batch normalization}{15}{subsubsection.3.4.3}\protected@file@percent }
\citation{raoballard1999}
\citation{millidge2021predictive}
\citation{PredictiveCodingNetworks}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Predictive coding network with 2 input nodes, 3 hidden nodes and 2 output nodes.\relax }}{16}{figure.caption.6}\protected@file@percent }
\newlabel{fig:predictive-coding-network}{{3}{16}{Predictive coding network with 2 input nodes, 3 hidden nodes and 2 output nodes.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Testing spiking neural networks}{16}{subsubsection.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Predictive Coding}{16}{subsection.3.5}\protected@file@percent }
\citation{PredictiveCodingNetworks}
\citation{PredictiveCodingNetworks}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Predictive coding networks and inference learning}{17}{subsubsection.3.5.1}\protected@file@percent }
\newlabel{eq:pc-error-nodes-and-preds}{{40}{17}{Predictive coding networks and inference learning}{equation.3.40}{}}
\newlabel{eq:update-value-nodes}{{42}{17}{Predictive coding networks and inference learning}{equation.3.42}{}}
\newlabel{eq:il-weight-update}{{43}{17}{Predictive coding networks and inference learning}{equation.3.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Z-IL and equivalence to back-propagation}{18}{subsubsection.3.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Predictive coding networks for classification}{18}{subsubsection.3.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.4}Biological plausability}{19}{subsubsection.3.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{19}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{19}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{19}{section.6}\protected@file@percent }
\bibstyle{plain}
\bibdata{refs}
\bibcite{BengioLBL15}{1}
\bibcite{Bi10464}{2}
\bibcite{Boht2000SpikePropBF}{3}
\bibcite{EqProp}{4}
\bibcite{eshraghian2021training}{5}
\bibcite{Goodfellow-et-al-2016}{6}
\bibcite{he2015delving}{7}
\bibcite{resnet}{8}
\bibcite{hebb1949}{9}
\bibcite{lstm}{10}
\bibcite{hunsberger2015spiking}{11}
\bibcite{Eric2018}{12}
\bibcite{ioffe2015batch}{13}
\bibcite{mnist}{14}
\bibcite{millidge2021predictive}{15}
\bibcite{noekland2016direct}{16}
\bibcite{raoballard1999}{17}
\bibcite{rumelhart1986learning}{18}
\bibcite{PredictiveCodingNetworks}{19}
\bibcite{transformers}{20}
\gdef \@abspage@last{24}
